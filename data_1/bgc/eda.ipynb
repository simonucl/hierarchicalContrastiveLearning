{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './BlurbGenreCollection_EN_train.txt'\n",
    "dev_data_path = './BlurbGenreCollection_EN_dev.txt'\n",
    "test_data_path = './BlurbGenreCollection_EN_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train_data as xml\n",
    "data = \"\"\n",
    "train_data = []\n",
    "with open(train_data_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        data += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58715/58715 [00:00<00:00, 209490.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "176558"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = ET.fromstring(data.replace('&', '&amp;'))\n",
    "total_labels = 0\n",
    "train_data_dict = []\n",
    "for book in tqdm(train_data.findall('book'), total = len(train_data.findall('book'))):\n",
    "    \n",
    "    # check the keys\n",
    "    title = book.find('title').text\n",
    "    text = book.find('body').text\n",
    "    i = 0\n",
    "    labels = []\n",
    "    topics = book.find('metadata').find('topics')\n",
    "\n",
    "    while True:\n",
    "        label = topics.findall(f'd{str(i)}')\n",
    "        if len(label) == 0:\n",
    "            break\n",
    "        for l in label:\n",
    "            total_labels += 1\n",
    "            labels.append(l.text)\n",
    "        i += 1\n",
    "    train_data_dict.append({'token': 'Title: ' + title + '. ' + 'Text: ' + text, 'label': labels})\n",
    "\n",
    "# store the train_data_dict as json lines\n",
    "with open('./train_data.jsonl', 'w') as f:\n",
    "    for data in train_data_dict:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing for dev_data\n",
    "data = \"\"\n",
    "dev_data = []\n",
    "with open(dev_data_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        data += line\n",
    "\n",
    "dev_data = ET.fromstring(data.replace('&', '&amp;'))\n",
    "\n",
    "dev_data_dict = []\n",
    "for book in dev_data.findall('book'):\n",
    "\n",
    "    # check the keys\n",
    "    title = book.find('title').text\n",
    "    text = book.find('body').text\n",
    "    i = 0\n",
    "    labels = []\n",
    "    topics = book.find('metadata').find('topics')\n",
    "\n",
    "    while True:\n",
    "        label = topics.findall(f'd{str(i)}')\n",
    "        if len(label) == 0:\n",
    "            break\n",
    "        for l in label:\n",
    "            labels.append(l.text)\n",
    "        i += 1\n",
    "    dev_data_dict.append({'token': 'Title: ' + title + '. ' + 'Text: ' + text, 'label': labels})\n",
    "    \n",
    "# store the dev_data_dict as json lines\n",
    "with open('./dev_data.jsonl', 'w') as f:\n",
    "    for data in dev_data_dict:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing for test_data\n",
    "data = \"\"\n",
    "test_data = []\n",
    "with open(test_data_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        data += line\n",
    "\n",
    "test_data = ET.fromstring(data.replace('&', '&amp;'))\n",
    "\n",
    "test_data_dict = []\n",
    "for book in test_data.findall('book'):\n",
    "        \n",
    "        # check the keys\n",
    "        title = book.find('title').text\n",
    "        text = book.find('body').text\n",
    "        i = 0\n",
    "        labels = []\n",
    "        topics = book.find('metadata').find('topics')\n",
    "    \n",
    "        while True:\n",
    "            label = topics.findall(f'd{str(i)}')\n",
    "            if len(label) == 0:\n",
    "                break\n",
    "            for l in label:\n",
    "                labels.append(l.text)\n",
    "            i += 1\n",
    "        test_data_dict.append({'token': 'Title: ' + title + '. ' + 'Text: ' + text, 'label': labels})\n",
    "\n",
    "# store the test_data_dict as json lines\n",
    "with open('./test_data.jsonl', 'w') as f:\n",
    "    for data in test_data_dict:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_set = set()\n",
    "for data in train_data_dict:\n",
    "    for label in data['label']:\n",
    "        train_label_set.add(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the hierarchy\n",
    "from collections import defaultdict\n",
    "hiera = defaultdict(list)\n",
    "labels = set()\n",
    "with open('./hierarchy.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split('\\t')\n",
    "        labels.add(line[0])\n",
    "        if len(line) != 2:\n",
    "            continue\n",
    "        labels.add(line[1])\n",
    "        if (line[0] not in train_label_set) or (line[1] not in train_label_set):\n",
    "            continue\n",
    "        else:\n",
    "            hiera[line[0]].append(line[1])\n",
    "\n",
    "labels = train_label_set\n",
    "\n",
    "r_hiera = {}\n",
    "for parent, childrens in hiera.items():\n",
    "    for children in childrens:\n",
    "        r_hiera[children] = parent\n",
    "\n",
    "# get the labels that are not in the r_hiera keys\n",
    "labels = list(labels)\n",
    "for label in labels:\n",
    "    if label not in r_hiera.keys():\n",
    "        r_hiera[label] = 'Root'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Childrens Media Tie-In Books',\n",
       " 'Children’s Activity & Novelty Books',\n",
       " 'Children’s Board Books',\n",
       " 'Children’s Boxed Sets',\n",
       " 'Children’s Chapter Books',\n",
       " 'Children’s Picture Books'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_set = set()\n",
    "for data in train_data_dict:\n",
    "    for label in data['label']:\n",
    "        train_label_set.add(label)\n",
    "set(labels) - train_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 34000, 2: 18445, 3: 5656, 4: 606, 5: 8})\n",
      "Counter({1: 8507, 2: 4659, 3: 1456, 4: 161, 5: 2})\n",
      "Counter({1: 10636, 2: 5800, 3: 1763, 4: 193, 5: 2})\n"
     ]
    }
   ],
   "source": [
    "def compute_path_no(labels):\n",
    "    visited = set()\n",
    "    paths = defaultdict(list)\n",
    "    path = 0\n",
    "    for label in labels:\n",
    "        if label in visited:\n",
    "            continue\n",
    "        visited.add(label)\n",
    "        while label != 'Root':\n",
    "            if label not in paths:\n",
    "                paths[label] = []\n",
    "            paths[r_hiera[label]].append(label)\n",
    "\n",
    "            label = r_hiera[label]\n",
    "            visited.add(label)\n",
    "            if label in visited:\n",
    "                break\n",
    "    path = np.sum([1 for path in paths.values() if len(path) < 1])\n",
    "\n",
    "    return path\n",
    "\n",
    "# compute the path number for each train_data\n",
    "for data in train_data_dict:\n",
    "    data['path_no'] = compute_path_no(data['label'])\n",
    "for data in dev_data_dict:\n",
    "    data['path_no'] = compute_path_no(data['label'])\n",
    "for data in test_data_dict:\n",
    "    data['path_no'] = compute_path_no(data['label'])\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter([data['path_no'] for data in train_data_dict]))\n",
    "print(Counter([data['path_no'] for data in dev_data_dict]))\n",
    "print(Counter([data['path_no'] for data in test_data_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = [k for k, v in r_hiera.items() if v == 'Root']\n",
    "with open('./bgc.taxonomy', 'w') as f:\n",
    "    queue = []\n",
    "    f.write('Root\\t')\n",
    "    f.write('\\t'.join(root))\n",
    "    queue.extend(root)\n",
    "\n",
    "    f.write('\\n')\n",
    "    while len(queue) > 0:\n",
    "        parent = queue.pop(0)\n",
    "        if parent in hiera:\n",
    "            f.write(parent + '\\t')\n",
    "            f.write('\\t'.join(hiera[parent]))\n",
    "            queue.extend(hiera[parent])\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiera, _label_dict, r_hiera, label_depth = get_hierarchy_info('./bgc.taxonomy')\n",
    "\n",
    "\n",
    "# dump _label_dict as value_dict.pt\n",
    "torch.save(_label_dict, './value_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_hier = dict(hiera)\n",
    "label_hier.pop('Root')\n",
    "\n",
    "label_hier = {_label_dict[k]: set([_label_dict[v] for v in vs]) for k, vs in label_hier.items()}\n",
    "label_hier\n",
    "\n",
    "with open('./slot.pt', 'wb') as f:\n",
    "    torch.save(label_hier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {7, 8},\n",
       " 2: {9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21},\n",
       " 3: {22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39},\n",
       " 4: {40, 41, 42, 43, 44, 45, 46, 47, 48},\n",
       " 5: {49, 50, 51, 52},\n",
       " 7: {53, 54, 55, 56, 57},\n",
       " 9: {58, 59, 60, 61},\n",
       " 13: {62, 63, 64, 65, 66},\n",
       " 14: {67, 68, 69, 70, 71, 72, 73, 74},\n",
       " 15: {75, 76, 77},\n",
       " 22: {78, 79},\n",
       " 24: {80, 81, 82, 83, 84},\n",
       " 28: {85, 86, 87, 88, 89, 90, 91, 92, 93, 94},\n",
       " 30: {95, 96, 97},\n",
       " 31: {98, 99},\n",
       " 32: {100, 101, 102, 103},\n",
       " 33: {104, 105, 106},\n",
       " 34: {107, 108, 109, 110},\n",
       " 35: {111, 112},\n",
       " 36: {113, 114, 115},\n",
       " 37: {116, 117, 118, 119, 120, 121, 122},\n",
       " 38: {123, 124, 125},\n",
       " 39: {126, 127, 128, 129},\n",
       " 95: {130, 131, 132, 133, 134, 135},\n",
       " 96: {136, 137, 138},\n",
       " 97: {139, 140, 141, 142, 143, 144, 145}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('multi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db59ca23d7a8a7d7288e0db7c0d6525aaf9834e40000b64f0ef663d84d9884f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
